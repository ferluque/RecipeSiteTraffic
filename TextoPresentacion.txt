Hello my name is ... and I'm presenting the Practical Exam about Recipe Site Traffic for the Datacamp 
certification.

1. First I would like to make a short overview on the project. 

On first place, the goal of the project was to develop a model that could predict if a recipe 
shown in home page will lead to an increase in website traffic

The requirements set by the product manager were to be able to predict 80% of high traffic recipes

The tools given were the data extracted by the Product Manager, which didn't include all available
information about the recipes, an important point we will discuss later.

2. The work done is the enumerated here:

A Data Validation process to analyse features and deal with missing values

An exploratory analysis to check independence between features, analyse distributions,
detect outliers and analyse the dependence of the target variable on different features

The development of the classification model, where I have developed 3 models: 1 "not so dummy"
classifier, one Logistic Regression classifier, and Random Forest classifier to check if 
LR was so simple

Last, the evaluation of the model.

3. I have dealed with 3 metrics:
the accuracy which measures the overall performance of the model
the precision which shows how accurate is the model in the positive class
the recall which shows how many true positives can capture our model

The requirement set by the product manager was the recall to be higher than 80%

4. The results obtained where those shown. I don't include the RandomForest classifier results
because they are similar to the Logistic Classifier.

About the dummy classifier, the only thing it does is to remember the majority class in each category
in the training set and returns the corresponding outcome depending on the new income recipe category.

With respect to the Logistic Classifier, we can see that giving more importance to the positive class
(that's what the term unbalanced means), we can achieve this 80% recall to the detriment of the
precision metric.

5. Translated to business metrics what these results mean is:
* On one hand, an 82% recall mean that from all the recipes that truly will lead to an increase on 
traffic, our model captures effectively 82% of them
* On the other hand, an 62,5% precision mean that only a bit more than the half recipes that our model
classifies as high traffic, will truly mean real high traffic.

Then the problem will be that the model will select a lot of recipes that won't really lead to high
traffic

6. So, in conclussion, I would say these are not very satisfactory results and these 2 could be the
main factors:
	1. Inssuficient or uninteresting features
	2. Limited data quantity
	
So my recommendation will be to repeat the experiment with other or more features such as the number
of ingredients, the cost of the recipe or preparation time.

If it wouldn't work, I will try to collect more data.

And that would be all from my side.
Thank you for your interest.